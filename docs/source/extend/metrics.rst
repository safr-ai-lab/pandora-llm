Metrics
=======

You may also wish to include a new metric or evlauation plot that allows you to measure different dimensions of privacy leakage.

1. Add the function to compute the metric in ``pandora_llm.utils.plot_utils``

.. code:: python
    
    def compute_metric(ground_truth, predictions, **kwargs):
        
        metric = metric_fn(ground_truth,predictions)
        
        return metric

2. It is good practice to include the option of computing the 95% confidence interval.
This is a template that will enable you to compute the bootstrapped confidence interval for potentially multiple statistics at the same time.

.. code:: python

    def compute_metric_with_ci(ground_truth, predictions, **kwargs):

        metric = metric_fn(ground_truth,predictions)

        def metric_bootstrap(data,axis):
            ground_truth = data[0,0,:].T
            predictions = data[1,0,:].T
            metric = metric_fn(ground_truth, predictions)
            other_derived_values = ... 
            return np.array([[metric]+[other_derived_values]]).T
        
        data = torch.cat((ground_truth[:,None],predictions[:,None]),dim=1)
        from scipy.stats import bootstrap
        bootstrap_result = bootstrap((data,), metric_bootstrap, confidence_level=0.95, n_resamples=num_bootstraps, batch=1, method='percentile',axis=0)
        metric_se = bootstrap_result.standard_error[0]
        other_derived_values_se = bootstrap_result.standard_error[1:]

        return metric, metric_se

3. Plotting can be done with the plotting library of your choice. Here is an example in ``matplotlib`` for ROC.

.. code:: python
    
    def plot_metric(ground_truth, predictions, **kwargs):
        
        ...
    
        plt.figure(figsize=(7,7),dpi=300)
        plt.plot([0, 1], [0, 1], linestyle="--", c="k")
        if not log_scale:
            plt.plot(fpr, tpr, label=f'AUC = {roc_auc:0.4f}',c=color)
            plt.xlim([0,1] if lims is None else lims)
            plt.ylim([0,1] if lims is None else lims)
        else:
            plt.loglog(fpr, tpr, label=f'AUC = {roc_auc:0.4f}',c=color)
            plt.xlim([10**(-int(np.log10(n_points))),1] if lims is None else lims)
            plt.ylim([10**(-int(np.log10(n_points))),1] if lims is None else lims)
        if ci:
            plt.fill_between(fpr_range,bootstrap_result.confidence_interval.low[1:],bootstrap_result.confidence_interval.high[1:],alpha=0.1,color=color)
        plt.title(plot_title)
        plt.legend(loc="lower right")
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.gca().set_aspect('equal', adjustable='box')
        plt.minorticks_on()
        plt.grid(which="major",alpha=0.2)
        plt.grid(which="minor",alpha=0.1)
    
        ...

4. Recommended: add a route to call the plotting utility through the ``MIA`` base class.

See for instance, the ROC curve function (shown below).

.. code:: python

    class MIA:

        ...

        def attack_plot_ROC(self, train_statistics, val_statistics, title, log_scale=False, show_plot=True, save_name=None):
            """
            Generates and displays or saves a plot of the ROC curve for the membership inference attack.

            This method uses the inputted statistics to create a ROC curve that 
            illustrates the performance of the attack. The plot can be displayed in a log scale, 
            shown directly, or saved to a file.

            Args:
                train_statistics (Iterable[float]): Statistics of the training set. Lower means more like train.
                val_statistics (Iterable[float]): Statistics of the validation set. Lower means more like train.
                title (str): The title for the ROC plot.
                log_scale (bool, optional): Whether to plot the ROC curve on a logarithmic scale. 
                    Defaults to False.
                show_plot (bool, optional): Whether to display the plot. If False, the plot is not 
                    shown but is saved directly to the file specified by `save_name`. Defaults to True.
                save_name (str, optional): The file name or path to save the plot image. If not 
                    specified, the default name is generated by the given title with an 
                    appropriate file extension. Defaults to None.
            """
            if save_name is None:
                save_name = title + ("_log" if log_scale else "")
            plot_ROC(train_statistics, val_statistics, title, log_scale=log_scale, show_plot=show_plot, save_name=save_name)
            plot_ROC_plotly(train_statistics, val_statistics, title, log_scale=log_scale, show_plot=show_plot, save_name=save_name)

.. note::

   Certain attack classes overwrite the base ``MIA`` plotting methods; e.g., ``MinK`` and ``GradNorm``, which are attacks that do not output a single statistic.
   In these cases, you should also add overwrite your new plotting method in the relevant attack classes.